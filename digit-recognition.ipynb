{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Kevin Delassus - G00270791"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Purpose\n",
    "The purpose of this notebook is to explain now the script file [digitrec.py](http://localhost:8888/edit/digitrec.py) works and also explain its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There can be many challanges assoiated to detecting hand written digits. If we take a human for example, humans and effortly recognize digits due to humans having a primary cortex in each hemisphere of our brain. Each primary cortex contains 140 million neurons and tens of billons of connections yet human vision involves not just primary cortex, but an entire series of visual cortices doing progressively more complex image processing. Recognizing handwritten digits isn't easy. Rather, we humans are stupendously, astoundingly good at making sense of what our eyes show us. But nearly all that work is done unconsciously. And so we don't usually appreciate how tough a problem our visual systems solve.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://alleninstitute.org/media/filer_public/74/44/74443675-6280-49a1-8362-61cecb90681c/neurons_all_16_large_blackbg-reid.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programming a Neural Networks makes this problem of digit detection easier to solve. To do this I used Keras to create the neural network. [Keras](https://keras.io/) is a high-level neural networks API, written in Python and capable of running on top of TensorFlow. Another great reason for using Keras is that it already contains the MNIST dataset meaning we don't need to go de-compress the train and test files.\n",
    "\n",
    "I used a Convolutional Neural Networks apposed to a using simple Neural Network due to it being more accurate. This will be explained in more detail below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
